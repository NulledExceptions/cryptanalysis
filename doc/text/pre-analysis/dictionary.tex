\subsection{Словарный перебор}
Наиболее простой метод — сравнение всех слов текста со словарем 
корректных слов нужного языка. Полученное количество совпавших слов
делится на количество слов исследуемого текста. Результирующая 
величина может рассматриваться как вероятность того, что данный 
текст принадлежит рассматриваемому языку.

Подобная оценка подходит целям данной работы — критерий по 
этой 'вероятности' позволит отделить зерна от плевел и выделить 
наиболее пригодный вариант — ложное срабатывание в общем случае 
маловероятно из-за специфики процесса. При негативном результате мы видим 
несвязный набор символов.

\begin{listing}[1]{1}
In [1]: import linguistics
In [2]: a = open('../sample/warandpeace', 'r').readlines()
In [3]: linguistics.define_language_dict(a)
('ru', 0,864536523576)
\end{listing}

Практика демонстрирует жизнеспособность такого метода. Во-первых, 
составление 
словаря для известного языка в необходимой стилистике не представляет 
трудности при условии доступности интернета. Во-вторых, современные 
компьютерные мощности позволяют сравнительно быстрое выполнение 
подобного анализа:

\begin{listing}[1]{1}
# /usr/bin/time python ./cipher/linguistics.py -d ./sample/warandpeace 
python  710.10s user 780.55s system 0% cpu 20.002 total
\end{listing}

Возможно совершествование данного метода путем написания более 
эффективных структур для хранения словаря, грамотной сериализации и 
использования оптимизированных алгоримов поиска по сортированному 
массиву. Но, как будет показано, в этом нет необходимости.
Во-первых мы не перешагнем известное ограничение сложности в 
$O(log(n))$ для алгоритмов поиска. Во-вторых, отсустствует необходимость 
в строгом соответствии текста языку определенному в словаре.
