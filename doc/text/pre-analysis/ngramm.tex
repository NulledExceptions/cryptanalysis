\subsection{N-граммы}
\DEF\textit{N-грамма} — последовательность из n элементов. С семантической точки зрения
, это может быть последовательность звуков, слогов, слов или букв. На практике 
чаще встречается N-грамма как ряд слов. Последовательность из двух последовательных 
элементов часто называют биграммы, последовательность из трех элементов 
называется триграмма. Не менее четырех и выше элементов обозначаются как 
N-грамма, N заменяется на количество последовательных элементов.

В области обработки естественного языка, N-граммы используется в основном для предугадывания на основе вероятностных моделей. N-граммная модель рассчитывает вероятность последнего слова N-граммы, если известны все предыдущие. При использовании этого подхода для моделирования языка предполагается, что появление каждого слова зависит только от предыдущих слов.

\DEF\textit{Инвертированный индекс} (англ. inverted index) — структура данных, в которой для каждого слова коллекции документов в соответствующем списке перечислены все места в коллекции, в которых оно встретилось. Инвертированный индекс используется для поиска по текстам.

Опишем как решается задача нахождения документов в которых встречаются все слова из поискового запроса. При обработке однословного поискового запроса, ответ уже есть в инвертированном индексе — достаточно взять список соответствующий слову из запроса. При обработке многословного запроса берутся списки, соответствующие каждому из слов запроса и пересекаются.

Пусть у нас есть корпус из трех текстов $T_0$="it is what it is", $T_1$="what is it" и $T_2$="it is a banana", тогда инвертированный индекс будет выглядеть следующим образом:

"a":      {2}

"banana": {2}

"is":     {0, 1, 2}

"it":     {0, 1, 2}

"what":   {0, 1}

Здесь цифры обозначают номера текстов, в которых встретилось соответствующее слово. Тогда отработка поискового "what is it" запроса даст следующий результат $\{0,1\} \cap \{0,1,2\} \cap \{0,1,2\} = \{0,1\}$.

In [1]: import linguistics

In [2]: a = open('../sample/warandpeace', 'r').readlines()

In [3]: linguistics.define\_language\_wgramms(a)

('ru', 0,892340923846)

Время исполнения такого теста так-же в разы превышает результат с словарями:

\$ time python ./cipher/linguistics.py -w ./sample/warandpeace 

python  210.10s user 280.55s system 0% cpu 20.002 total

